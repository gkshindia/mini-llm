{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "574a1f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_embs): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from architecture import GPTModel\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    vocab_size: int = 50257\n",
    "    context_length: int = 256\n",
    "    em_dim: int = 768\n",
    "    n_heads: int = 12\n",
    "    n_layers: int = 12\n",
    "    drop_rate: float = 0.1\n",
    "    qkv_bias: bool = False\n",
    "\n",
    "GPT_CONFIG_124M = GPTConfig()\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81c09325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]  # focus on last time step\n",
    "        probabs = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probabs, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n",
    "\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded, dtype=torch.long).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M.context_length,\n",
    ")\n",
    "print(\"Generated text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf6a384f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters in Naval Ravikant text: 20479\n",
      "Total tokens in Naval Ravikant text: 5145\n"
     ]
    }
   ],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "total_characters = len(raw_text)\n",
    "total_tokens = len(tokenizer.encode(raw_text))\n",
    "print(f\"Total characters in Naval Ravikant text: {total_characters}\")\n",
    "print(f\"Total tokens in Naval Ravikant text: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70c2473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(len(raw_text) * train_ratio)\n",
    "train_data = raw_text[:split_idx]\n",
    "val_data = raw_text[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a646b929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "Validation loader\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of \n",
    "        # max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size, max_length, stride,\n",
    "                         shuffle=True, drop_last=True, num_workers=0):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, \n",
    "        num_workers=num_workers)\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    txt=train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M.context_length,\n",
    "    stride=GPT_CONFIG_124M.context_length,\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    txt=val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M.context_length,\n",
    "    stride=GPT_CONFIG_124M.context_length,\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "print(\"Train loader\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"Validation loader\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be799d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropy loss function\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0,1), target_batch.flatten()\n",
    "    )\n",
    "    return loss \n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be1eb1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 10.9876, Validation loss: 10.9811\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(f\"Train loss: {train_loss:.4f}, Validation loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4245d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 0: \n",
      "Train loss: 9.9229, Val Loss = 10.0632\n",
      "Epoch 1, Step 5: \n",
      "Train loss: 8.4352, Val Loss = 8.6530\n",
      "Generated text:\n",
      " Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Epoch 2, Step 10: \n",
      "Train loss: 7.1425, Val Loss = 7.4894\n",
      "Epoch 2, Step 15: \n",
      "Train loss: 6.2367, Val Loss = 6.8130\n",
      "Generated text:\n",
      " Every effort moves you, and, and, and, and, and, and, and, and,, and,, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Epoch 3, Step 20: \n",
      "Train loss: 5.8652, Val Loss = 6.5411\n",
      "Epoch 3, Step 25: \n",
      "Train loss: 5.3603, Val Loss = 6.3438\n",
      "Generated text:\n",
      " Every effort moves you, and I had\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 4, Step 30: \n",
      "Train loss: 5.1669, Val Loss = 6.4355\n",
      "Epoch 4, Step 35: \n",
      "Train loss: 4.6938, Val Loss = 6.2862\n",
      "Generated text:\n",
      " Every effort moves you, and, and I was a of the picture, I had been.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 5, Step 40: \n",
      "Train loss: 4.2687, Val Loss = 6.1691\n",
      "Generated text:\n",
      " Every effort moves you know the, and in the picture of the picture.\n",
      "\n",
      "\n",
      "\n",
      "\".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"Oh, and to me.\n",
      "\"--as his pictures--and it.\n",
      "\"I, and the of the picture.\n",
      "\n",
      "Epoch 6, Step 45: \n",
      "Train loss: 3.5815, Val Loss = 6.1811\n",
      "Epoch 6, Step 50: \n",
      "Train loss: 3.2325, Val Loss = 6.1558\n",
      "Generated text:\n",
      " Every effort moves you know the to see a little of his pictures--I had a little of a little: \"--his, in fact, and in to the picture, and I had been, and in the sketch of the, and down, and he was his\n",
      "Epoch 7, Step 55: \n",
      "Train loss: 2.9310, Val Loss = 6.1804\n",
      "Epoch 7, Step 60: \n",
      "Train loss: 2.7414, Val Loss = 6.2328\n",
      "Generated text:\n",
      " Every effort moves you know; and, and I felt--I to the fact with a little a little: \"--I looked up, I had been to the picture, and I had been his pictures--and it, the donkey, and, and he was his\n",
      "Epoch 8, Step 65: \n",
      "Train loss: 2.1909, Val Loss = 6.1793\n",
      "Epoch 8, Step 70: \n",
      "Train loss: 1.7983, Val Loss = 6.1901\n",
      "Generated text:\n",
      " Every effort moves you know,\" was one of the picture for nothing--I had the picture.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "He laughed again, and threw back his head to look up at the honour him, and in the fact--I was.\n",
      "Epoch 9, Step 75: \n",
      "Train loss: 1.5207, Val Loss = 6.1876\n",
      "Epoch 9, Step 80: \n",
      "Train loss: 1.2284, Val Loss = 6.2625\n",
      "Generated text:\n",
      " Every effort moves you know,\" was not that my hostess was \"interesting\": on that point I could have given Miss Croft the fact, had been to the display of his painting.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"I turned, and were, and in his\n",
      "Epoch 10, Step 85: \n",
      "Train loss: 0.9791, Val Loss = 6.3110\n",
      "Generated text:\n",
      " Every effort moves you know,\" was one of the axioms he had been the frame called up all Gisburn's past!\n",
      "\n",
      "He laughed again, and threw back the window-curtains, as I turned, and down the room, the first\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(mode, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model,\n",
    "            idx=encoded,\n",
    "            max_new_tokens=50,\n",
    "            context_size=context_size,\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(\"Generated text:\\n\", decoded_text)\n",
    "    model.train()\n",
    "\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_steps = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_steps += 1\n",
    "\n",
    "            if global_steps % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch {epoch+1}, Step {global_steps}: \\n\"\n",
    "                    f\"Train loss: {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "                \n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.1)\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=start_context,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af2419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_loss, val_loss):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()                   #1\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)     #2\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
    "\n",
    "# model is overfitting the training data, since we are working with a small dataset, and training the model for many epochs.\n",
    "# To mitigate overfitting, we can consider techniques such as using a larger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2976fb1f",
   "metadata": {},
   "source": [
    "## Text Generation (decoding) Strategy\n",
    "#### temperature scaling and top-k sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5240281d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      " Every effort moves you know,\" was one of the axioms he had been the frame called up all Gisburn's past!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M.context_length,\n",
    ")\n",
    "print(\"Generated text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "\n",
    "# gneerated text remains consistent , corresponding to the largest probability score. basically greedy decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5065ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f519d77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      " Every effort moves you not to work on surprise, a picture to have been the end by by\n"
     ]
    }
   ],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]  # focus on last time step\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        \n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        \n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    \n",
    "    return idx\n",
    "\n",
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M.context_length,\n",
    "    temperature=1.3,\n",
    "    top_k=25\n",
    ")\n",
    "print(\"Generated text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a99b3",
   "metadata": {},
   "source": [
    "### Loading pretrained weights from OpenAI GPT-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "090a43d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow>=2.15.0 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (2.20.0)\n",
      "Requirement already satisfied: tqdm>=4.66 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (6.33.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (2.2.6)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorflow>=2.15.0) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow>=2.15.0) (3.10)\n",
      "Requirement already satisfied: pillow in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow>=2.15.0) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow>=2.15.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow>=2.15.0) (3.1.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.15.0) (0.45.1)\n",
      "Requirement already satisfied: rich in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow>=2.15.0) (14.2.0)\n",
      "Requirement already satisfied: namex in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow>=2.15.0) (0.1.0)\n",
      "Requirement already satisfied: optree in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow>=2.15.0) (0.18.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow>=2.15.0) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow>=2.15.0) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow>=2.15.0) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/donna/Documents/selfie/repos/mini-llm/.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow>=2.15.0) (0.1.2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"tensorflow>=2.15.0\", \"tqdm>=4.66\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64aa5065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77.0/77.0 [00:00<00:00, 128kiB/s]\n",
      "encoder.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.04M/1.04M [00:02<00:00, 465kiB/s] \n",
      "hparams.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90.0/90.0 [00:00<00:00, 50.4kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498M/498M [23:44<00:00, 349kiB/s]    \n",
      "model.ckpt.index: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.21k/5.21k [00:00<00:00, 3.16MiB/s]\n",
      "model.ckpt.meta: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 471k/471k [00:01<00:00, 269kiB/s]  \n",
      "vocab.bpe: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:01<00:00, 235kiB/s]  \n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
