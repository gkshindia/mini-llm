{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d1b0e6",
   "metadata": {},
   "source": [
    "## Naive Self Attention without Trainable weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcd331ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention scores: tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")\n",
    "\n",
    "query = inputs[1]\n",
    "\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query)\n",
    "\n",
    "print(\"Attention scores:\", attn_scores_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d190782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights (generic normalization): tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum: tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "# generic normalization\n",
    "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
    "print(\"Attention weights (generic normalization):\", attn_weights_2_tmp)\n",
    "print(\"Sum:\", attn_weights_2_tmp.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9055d8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights (naive softmax): tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# naive softmax function\n",
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "\n",
    "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
    "print(\"Attention weights (naive softmax):\", attn_weights_2_naive)\n",
    "print(\"Sum:\", attn_weights_2_naive.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0439a087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights (torch softmax): tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# standard torch softmax\n",
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "print(\"Attention weights (torch softmax):\", attn_weights_2)\n",
    "print(\"Sum:\", attn_weights_2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b76e0aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: tensor([0.0596, 0.0208, 0.1233])  (attention  tensor(0.1385) ; input  tensor([0.4300, 0.1500, 0.8900]) )\n",
      "Step 1: tensor([0.1904, 0.2277, 0.2803])  (attention  tensor(0.2379) ; input  tensor([0.5500, 0.8700, 0.6600]) )\n",
      "Step 2: tensor([0.3234, 0.4260, 0.4296])  (attention  tensor(0.2333) ; input  tensor([0.5700, 0.8500, 0.6400]) )\n",
      "Step 3: tensor([0.3507, 0.4979, 0.4705])  (attention  tensor(0.1240) ; input  tensor([0.2200, 0.5800, 0.3300]) )\n",
      "Step 4: tensor([0.4340, 0.5250, 0.4813])  (attention  tensor(0.1082) ; input  tensor([0.7700, 0.2500, 0.1000]) )\n",
      "Step 5: tensor([0.4419, 0.6515, 0.5683])  (attention  tensor(0.1581) ; input  tensor([0.0500, 0.8000, 0.5500]) )\n",
      "Context vector: tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "# context evctor\n",
    "query = inputs[1]\n",
    "context_vector_2 = torch.zeros(query.shape)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    context_vector_2 += attn_weights_2[i] * x_i\n",
    "    print(f\"Step {i}:\", context_vector_2, \" (attention \", attn_weights_2[i], \"; input \", x_i, \")\")\n",
    "print(\"Context vector:\", context_vector_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1cba63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention scores matrix:\n",
      " tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n",
      "Attention scores matrix (matrix multiplication):\n",
      " tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n",
      "Normalized Attention weights matrix:\n",
      " tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n",
      "Context vectors:\n",
      " tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Steps - \n",
    "1. Compute attention scores as dot products between query and each input.\n",
    "2. Normalize attention scores using PyTorch softmax.\n",
    "3. Compute context vector as weighted sum of inputs using attention weights.\n",
    "\"\"\"\n",
    "\n",
    "attn_scores = torch.empty(6, 6)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    for j, x_j in enumerate(inputs):\n",
    "        attn_scores[i, j] = torch.dot(x_i, x_j)\n",
    "print(\"Attention scores matrix:\\n\", attn_scores)\n",
    "\n",
    "# for loops ar slow - use matrix multiplication\n",
    "attn_scores_matmul = inputs @ inputs.T\n",
    "print(\"Attention scores matrix (matrix multiplication):\\n\", attn_scores_matmul)\n",
    "\n",
    "# normalize attention scores using softmax along rows\n",
    "attn_weights_matmul = torch.softmax(attn_scores_matmul, dim=-1)\n",
    "print(\"Normalized Attention weights matrix:\\n\", attn_weights_matmul)\n",
    "\n",
    "# compute context vectors for all inputs\n",
    "context_vectors = attn_weights_matmul @ inputs\n",
    "print(\"Context vectors:\\n\", context_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c32377",
   "metadata": {},
   "source": [
    "## Self Attention with trainable weights. (scaled dot-product attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6fdc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query vector: tensor([0.4306, 1.4551])\n",
      "Key vector: tensor([0.4433, 1.1419])\n",
      "Value vector: tensor([0.3951, 1.0037])\n",
      "Keys matrix:\n",
      " tensor([[0.3669, 0.7646],\n",
      "        [0.4433, 1.1419],\n",
      "        [0.4361, 1.1156],\n",
      "        [0.2408, 0.6706],\n",
      "        [0.1827, 0.3292],\n",
      "        [0.3275, 0.9642]]) shape: torch.Size([6, 2])\n",
      "Values matrix:\n",
      " tensor([[0.1855, 0.8812],\n",
      "        [0.3951, 1.0037],\n",
      "        [0.3879, 0.9831],\n",
      "        [0.2393, 0.5493],\n",
      "        [0.1492, 0.3346],\n",
      "        [0.3221, 0.7863]]) shape: torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2\n",
    "\n",
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "\n",
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "\n",
    "print(\"Query vector:\", query_2)\n",
    "print(\"Key vector:\", key_2)\n",
    "print(\"Value vector:\", value_2)\n",
    "\n",
    "# require key and value vectors for all inputs\n",
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "print(\"Keys matrix:\\n\", keys, \"shape:\", keys.shape)\n",
    "print(\"Values matrix:\\n\", values, \"shape:\", values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1f641c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention score w22: tensor(1.8524)\n",
      "Attention scores for query 2: tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n",
      "Attention weights for query 2: tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n",
      "Context vector for query 2: tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "source": [
    "# attention score w22\n",
    "keys_2 = keys[1]\n",
    "attn_scores_22 = query_2.dot(keys_2)\n",
    "print(\"Attention score w22:\", attn_scores_22)\n",
    "\n",
    "# generalize attention scores for all\n",
    "attn_scores_2 = query_2 @ keys.T\n",
    "print(\"Attention scores for query 2:\", attn_scores_2)\n",
    "\n",
    "d_k = keys.shape[-1]\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k ** 0.5, dim=-1)\n",
    "print(\"Attention weights for query 2:\", attn_weights_2)\n",
    "\n",
    "# context vector for query 2\n",
    "context_vector_2 = attn_weights_2 @ values\n",
    "print(\"Context vector for query 2:\", context_vector_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73592259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vectors from SelfAttention_v1:\n",
      " tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compact self attention class \n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value\n",
    "\n",
    "        attn_Scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_Scores / (keys.shape[-1] ** 0.5), dim=-1)\n",
    "        context_vectors = attn_weights @ values\n",
    "        return context_vectors\n",
    "\n",
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in=3, d_out=2)\n",
    "print(\"Context vectors from SelfAttention_v1:\\n\", sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0bd5152a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vectors from SelfAttention_v2:\n",
      " tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compact self attention class using nn.Linear\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / (keys.shape[-1] ** 0.5), dim=-1)\n",
    "        context_vectors = attn_weights @ values\n",
    "        return context_vectors\n",
    "\n",
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in=3, d_out=2)\n",
    "print(\"Context vectors from SelfAttention_v2:\\n\", sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cd9f6b",
   "metadata": {},
   "source": [
    "## Causal Self Attention with trainable weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f0c0caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights from SelfAttention_v2:\n",
      " tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
      "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
      "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "Simple lower triangular mask:\n",
      " tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n",
      "Masked attention weights (simple):\n",
      " tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Renormalized masked attention weights (simple):\n",
      " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa_v2.W_query(inputs)\n",
    "keys = sa_v2.W_key(inputs)\n",
    "attn_scores = queries @ keys.T\n",
    "attn_weights = torch.softmax(attn_scores / (keys.shape[-1] ** 0.5), dim=-1)\n",
    "print(\"Attention weights from SelfAttention_v2:\\n\", attn_weights)\n",
    "\n",
    "# create a mask\n",
    "context_length = attn_scores.shape[0]\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "print(\"Simple lower triangular mask:\\n\", mask_simple)\n",
    "\n",
    "masked_simple = attn_weights * mask_simple\n",
    "print(\"Masked attention weights (simple):\\n\", masked_simple)\n",
    "\n",
    "# renormalize = \n",
    "row_sums = masked_simple.sum(dim=-1, keepdim=True)\n",
    "masked_simple_norm = masked_simple / row_sums\n",
    "print(\"Renormalized masked attention weights (simple):\\n\", masked_simple_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fcdf29a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked attention scores (causal):\n",
      " tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# effecient causal self attention with mask\n",
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "print(\"Masked attention scores (causal):\\n\", masked) \n",
    "\n",
    "attn_weights = torch.softmax(masked / keys.shape[-1] ** 0.5, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1320ceda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n",
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.7599, 0.6194, 0.6206, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4921, 0.4925, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3966, 0.0000, 0.3775, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3327, 0.3331, 0.3084, 0.3331, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# dropping out attention weights\n",
    "\n",
    "torch.manual_seed(123)\n",
    "dropout = nn.Dropout(p=0.5)\n",
    "example = torch.ones(6,6)\n",
    "print(dropout(example))\n",
    "\n",
    "torch.manual_seed(123)\n",
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e0d62e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([2, 6, 3])\n",
      "Context vectors from CausalAttention:\n",
      " tensor([[[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]],\n",
      "\n",
      "        [[-0.4519,  0.2216],\n",
      "         [-0.5874,  0.0058],\n",
      "         [-0.6300, -0.0632],\n",
      "         [-0.5675, -0.0843],\n",
      "         [-0.5526, -0.0981],\n",
      "         [-0.5299, -0.1081]]], grad_fn=<UnsafeViewBackward0>) shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "# compact causal attention class\n",
    "\n",
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(\"Batch shape:\", batch.shape)\n",
    "\n",
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self, d_in,d_out, context_length, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1,2)\n",
    "        attn_scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] **0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_vectors = attn_weights @ values\n",
    "        return context_vectors\n",
    "\n",
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "context_vecs = ca(batch)\n",
    "print(\"Context vectors from CausalAttention:\\n\", context_vecs, \"shape:\", context_vecs.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea07a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multi-head Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "715f5293",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([\n",
    "            CausalAttention(d_in, d_out // num_heads, context_length, dropout, qkv_bias)\n",
    "            for _ in range(num_heads)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bbeb195d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vectors from MultiHeadAttentionWrapper:\n",
      " tensor([[[-0.5740,  0.2216],\n",
      "         [-0.7320,  0.0155],\n",
      "         [-0.7774, -0.0546],\n",
      "         [-0.6979, -0.0817],\n",
      "         [-0.6538, -0.0957],\n",
      "         [-0.6424, -0.1065]],\n",
      "\n",
      "        [[-0.5740,  0.2216],\n",
      "         [-0.7320,  0.0155],\n",
      "         [-0.7774, -0.0546],\n",
      "         [-0.6979, -0.0817],\n",
      "         [-0.6538, -0.0957],\n",
      "         [-0.6424, -0.1065]]], grad_fn=<CatBackward0>) shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "d_in, d_out = 3,2\n",
    "mha = MultiHeadAttentionWrapper(d_in, d_out, context_length, dropout=0.0, num_heads=2)\n",
    "context_vecs_mha = mha(batch)\n",
    "print(\"Context vectors from MultiHeadAttentionWrapper:\\n\", context_vecs_mha, \"shape:\", context_vecs_mha.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b75b6932",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, num_heads, dropout=0.0, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1,2)\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        return context_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "48c30126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vectors from MultiHeadAttention:\n",
      " tensor([[[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]],\n",
      "\n",
      "        [[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>) shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in, d_out, num_heads=2, dropout=0.0)\n",
    "context_vecs_mha = mha(batch)\n",
    "print(\"Context vectors from MultiHeadAttention:\\n\", context_vecs_mha, \"shape:\", context_vecs_mha.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
